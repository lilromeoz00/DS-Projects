{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":37,"outputs":[{"output_type":"stream","text":"/kaggle/input/creditcardfraud/creditcard.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the needed libraries\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\nfrom keras.optimizers import RMSprop, SGD, Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics   \nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb ","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/creditcardfraud/creditcard.csv')\ndf.head()","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating what we use for training and prediction\nX = df.drop(['Class'], axis=1)\nY = df['Class']\n# Spliting so we have an accurate idea of model performance\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 42)\nX_test, X_val, Y_test, Y_val = train_test_split(X_test,y_test, test_size=.5, random_state = 42)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shape for NN\nX_train.shape","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"(199364, 30)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First model, let's see how this holds up.\nmodel = Sequential()\n\nmodel.add(keras.layers.Dense(128, activation='relu', input_shape=(30,)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n\nprint('model defined :)')","execution_count":42,"outputs":[{"output_type":"stream","text":"model defined :)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the model\ncheckpoint = ModelCheckpoint('FraudDetectionModel.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n# Stopping at a certain number of epochs to save time if model isn't learning\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=5,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n# Reduce learning rate\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,checkpoint,reduce_lr]\n\nopt = keras.optimizers.Adam(lr=0.001)\n\n# Now put it all together\nmodel.compile(loss='binary_crossentropy',\n              optimizer = opt,\n              metrics=['accuracy'])","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First model let's train.\nhist = model.fit(X_train, y_train,\n        epochs=5,\n        validation_data=(X_val, Y_val),\n        callbacks = callbacks)","execution_count":44,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n6231/6231 [==============================] - 13s 2ms/step - loss: 0.0768 - accuracy: 0.9755 - val_loss: 0.0109 - val_accuracy: 0.9986\n\nEpoch 00001: val_loss improved from inf to 0.01091, saving model to FraudDetectionModel.h5\nEpoch 2/5\n6231/6231 [==============================] - 12s 2ms/step - loss: 0.0142 - accuracy: 0.9982 - val_loss: 0.0113 - val_accuracy: 0.9986\n\nEpoch 00002: val_loss did not improve from 0.01091\nEpoch 3/5\n6231/6231 [==============================] - 13s 2ms/step - loss: 0.0130 - accuracy: 0.9983 - val_loss: 0.7234 - val_accuracy: 0.9980\n\nEpoch 00003: val_loss did not improve from 0.01091\nEpoch 4/5\n6231/6231 [==============================] - 12s 2ms/step - loss: 0.0137 - accuracy: 0.9982 - val_loss: 0.6719 - val_accuracy: 0.9981\n\nEpoch 00004: val_loss did not improve from 0.01091\n\nEpoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\nEpoch 5/5\n6231/6231 [==============================] - 12s 2ms/step - loss: 0.0134 - accuracy: 0.9982 - val_loss: 0.3095 - val_accuracy: 0.9979\n\nEpoch 00005: val_loss did not improve from 0.01091\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, Y_test)[1]","execution_count":45,"outputs":[{"output_type":"stream","text":"1336/1336 [==============================] - 1s 852us/step - loss: 0.0573 - accuracy: 0.9978\n","name":"stdout"},{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"0.9977996945381165"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 99.72% Accuracy is amazing for the first go! Why did it stop learning after epoch 1? Maybe step count was too high.","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try it with decreased steps","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelB = Sequential()\n\nmodelB.add(keras.layers.Dense(128, activation='relu', input_shape=(30,)))\nmodelB.add(BatchNormalization())\nmodelB.add(Dropout(0.25))\nmodelB.add(keras.layers.Dense(128, activation='relu'))\nmodelB.add(BatchNormalization())\nmodelB.add(Dropout(0.25))\nmodelB.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n\nprint('modelB defined :)')\n\ncheckpointB = ModelCheckpoint('FraudDetectionModelB.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystopB = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=100,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lrB = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacksB = [earlystopB,checkpointB,reduce_lrB]\n\noptB = keras.optimizers.Adam(lr=0.001)\n\nmodelB.compile(loss='binary_crossentropy',\n              optimizer = optB,\n              metrics=['accuracy'])","execution_count":48,"outputs":[{"output_type":"stream","text":"modelB defined :)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"histB = modelB.fit(X_train, y_train,\n        epochs=10,\n        validation_data=(X_val, Y_val),\n        steps_per_epoch=50,\n        callbacks = callbacksB)","execution_count":49,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n50/50 [==============================] - 3s 50ms/step - loss: 0.7269 - accuracy: 0.6198 - val_loss: 0.3561 - val_accuracy: 0.9985\n\nEpoch 00001: val_loss improved from inf to 0.35613, saving model to FraudDetectionModelB.h5\nEpoch 2/10\n50/50 [==============================] - 2s 46ms/step - loss: 0.3975 - accuracy: 0.9107 - val_loss: 0.1764 - val_accuracy: 0.9986\n\nEpoch 00002: val_loss improved from 0.35613 to 0.17639, saving model to FraudDetectionModelB.h5\nEpoch 3/10\n50/50 [==============================] - 2s 47ms/step - loss: 0.1960 - accuracy: 0.9840 - val_loss: 0.0860 - val_accuracy: 0.9986\n\nEpoch 00003: val_loss improved from 0.17639 to 0.08601, saving model to FraudDetectionModelB.h5\nEpoch 4/10\n50/50 [==============================] - 2s 46ms/step - loss: 0.0908 - accuracy: 0.9957 - val_loss: 0.0464 - val_accuracy: 0.9986\n\nEpoch 00004: val_loss improved from 0.08601 to 0.04642, saving model to FraudDetectionModelB.h5\nEpoch 5/10\n50/50 [==============================] - 2s 47ms/step - loss: 0.0500 - accuracy: 0.9975 - val_loss: 0.0287 - val_accuracy: 0.9986\n\nEpoch 00005: val_loss improved from 0.04642 to 0.02873, saving model to FraudDetectionModelB.h5\nEpoch 6/10\n50/50 [==============================] - 2s 46ms/step - loss: 0.0337 - accuracy: 0.9980 - val_loss: 0.0228 - val_accuracy: 0.9986\n\nEpoch 00006: val_loss improved from 0.02873 to 0.02277, saving model to FraudDetectionModelB.h5\nEpoch 7/10\n50/50 [==============================] - 2s 47ms/step - loss: 0.0257 - accuracy: 0.9980 - val_loss: 0.0187 - val_accuracy: 0.9986\n\nEpoch 00007: val_loss improved from 0.02277 to 0.01866, saving model to FraudDetectionModelB.h5\nEpoch 8/10\n50/50 [==============================] - 2s 47ms/step - loss: 0.0223 - accuracy: 0.9981 - val_loss: 0.0161 - val_accuracy: 0.9986\n\nEpoch 00008: val_loss improved from 0.01866 to 0.01608, saving model to FraudDetectionModelB.h5\nEpoch 9/10\n50/50 [==============================] - 2s 46ms/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: 0.0139 - val_accuracy: 0.9986\n\nEpoch 00009: val_loss improved from 0.01608 to 0.01392, saving model to FraudDetectionModelB.h5\nEpoch 10/10\n50/50 [==============================] - 2s 49ms/step - loss: 0.0185 - accuracy: 0.9979 - val_loss: 0.0122 - val_accuracy: 0.9986\n\nEpoch 00010: val_loss improved from 0.01392 to 0.01225, saving model to FraudDetectionModelB.h5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelB.evaluate(X_test, Y_test)[1]","execution_count":50,"outputs":[{"output_type":"stream","text":"1336/1336 [==============================] - 1s 909us/step - loss: 0.0145 - accuracy: 0.9982\n","name":"stdout"},{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"0.998197615146637"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slightly better accuracy. May be due to the loss being able to increase steadily instead of sporadically\n# Graphs should look decent now","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(histB.history['loss'])\nplt.plot(histB.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()\nplt.plot(histB.history['accuracy'])\nplt.plot(histB.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelC = Sequential()\n\nmodelC.add(keras.layers.Dense(128, activation='relu', input_shape=(30,)))\nmodelC.add(BatchNormalization())\nmodelC.add(Dropout(0.25))\nmodelC.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n\nprint('modelC defined :)')\n\ncheckpointC = ModelCheckpoint('FraudDetectionModelC.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystopC = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=100,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lrC = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacksC = [earlystopC,checkpointC,reduce_lrC]\n\noptC = keras.optimizers.Adam(lr=0.001)\n\nmodelC.compile(loss='binary_crossentropy',\n              optimizer = optC,\n              metrics=['accuracy'])","execution_count":53,"outputs":[{"output_type":"stream","text":"modelC defined :)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"histC = modelC.fit(X_train, y_train,\n        epochs=10,\n        validation_data=(X_val, Y_val),\n        steps_per_epoch=50,\n        callbacks = callbacksC)","execution_count":54,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n50/50 [==============================] - 2s 37ms/step - loss: 0.6570 - accuracy: 0.6580 - val_loss: 0.4759 - val_accuracy: 0.9983\n\nEpoch 00001: val_loss improved from inf to 0.47589, saving model to FraudDetectionModelC.h5\nEpoch 2/10\n50/50 [==============================] - 2s 34ms/step - loss: 0.3320 - accuracy: 0.9518 - val_loss: 0.2074 - val_accuracy: 0.9986\n\nEpoch 00002: val_loss improved from 0.47589 to 0.20739, saving model to FraudDetectionModelC.h5\nEpoch 3/10\n50/50 [==============================] - 2s 33ms/step - loss: 0.1380 - accuracy: 0.9933 - val_loss: 0.1663 - val_accuracy: 0.9986\n\nEpoch 00003: val_loss improved from 0.20739 to 0.16629, saving model to FraudDetectionModelC.h5\nEpoch 4/10\n50/50 [==============================] - 2s 33ms/step - loss: 0.0643 - accuracy: 0.9974 - val_loss: 0.1111 - val_accuracy: 0.9986\n\nEpoch 00004: val_loss improved from 0.16629 to 0.11111, saving model to FraudDetectionModelC.h5\nEpoch 5/10\n50/50 [==============================] - 2s 33ms/step - loss: 0.0384 - accuracy: 0.9981 - val_loss: 0.0247 - val_accuracy: 0.9986\n\nEpoch 00005: val_loss improved from 0.11111 to 0.02474, saving model to FraudDetectionModelC.h5\nEpoch 6/10\n50/50 [==============================] - 2s 32ms/step - loss: 0.0274 - accuracy: 0.9981 - val_loss: 0.0174 - val_accuracy: 0.9986\n\nEpoch 00006: val_loss improved from 0.02474 to 0.01745, saving model to FraudDetectionModelC.h5\nEpoch 7/10\n50/50 [==============================] - 2s 32ms/step - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.0295 - val_accuracy: 0.9986\n\nEpoch 00007: val_loss did not improve from 0.01745\nEpoch 8/10\n50/50 [==============================] - 2s 32ms/step - loss: 0.0182 - accuracy: 0.9983 - val_loss: 0.0252 - val_accuracy: 0.9986\n\nEpoch 00008: val_loss did not improve from 0.01745\nEpoch 9/10\n50/50 [==============================] - 2s 32ms/step - loss: 0.0170 - accuracy: 0.9982 - val_loss: 0.0170 - val_accuracy: 0.9986\n\nEpoch 00009: val_loss improved from 0.01745 to 0.01699, saving model to FraudDetectionModelC.h5\nEpoch 10/10\n50/50 [==============================] - 2s 33ms/step - loss: 0.0158 - accuracy: 0.9981 - val_loss: 0.0154 - val_accuracy: 0.9986\n\nEpoch 00010: val_loss improved from 0.01699 to 0.01543, saving model to FraudDetectionModelC.h5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelC.evaluate(X_test, Y_test)[1]","execution_count":55,"outputs":[{"output_type":"stream","text":"1336/1336 [==============================] - 1s 781us/step - loss: 0.0174 - accuracy: 0.9982\n","name":"stdout"},{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"0.998197615146637"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Same accuracy.. Lets try something a bit different, but may work.","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Single Perceptron!\nmodelD = Sequential()\n\nmodelD.add(keras.layers.Dense(1, activation = \"sigmoid\", input_shape=(30,)))\n\nprint('modelD defined :)')\n\ncheckpointD = ModelCheckpoint('FraudDetectionModelD.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystopD = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=100,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lrD = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacksD = [earlystopD,checkpointD,reduce_lrD]\n\noptD = keras.optimizers.Adam(lr=0.001)\n\nmodelD.compile(loss='binary_crossentropy',\n              optimizer = optD,\n              metrics=['accuracy'])","execution_count":57,"outputs":[{"output_type":"stream","text":"modelD defined :)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"histD = modelD.fit(X_train, y_train,\n        epochs=10,\n        validation_data=(X_val, Y_val),\n        # This one wont need step changes\n        #steps_per_epoch=50,\n        callbacks = callbacksD)","execution_count":58,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n6231/6231 [==============================] - 7s 1ms/step - loss: 4493.9458 - accuracy: 0.7716 - val_loss: 0.8323 - val_accuracy: 0.9986\n\nEpoch 00001: val_loss improved from inf to 0.83233, saving model to FraudDetectionModelD.h5\nEpoch 2/10\n6231/6231 [==============================] - 7s 1ms/step - loss: 0.7241 - accuracy: 0.9972 - val_loss: 2.2239 - val_accuracy: 0.9985\n\nEpoch 00002: val_loss did not improve from 0.83233\nEpoch 3/10\n6231/6231 [==============================] - 6s 1ms/step - loss: 0.8937 - accuracy: 0.9971 - val_loss: 0.7591 - val_accuracy: 0.9985\n\nEpoch 00003: val_loss improved from 0.83233 to 0.75909, saving model to FraudDetectionModelD.h5\nEpoch 4/10\n6231/6231 [==============================] - 7s 1ms/step - loss: 0.7972 - accuracy: 0.9966 - val_loss: 0.0615 - val_accuracy: 0.9975\n\nEpoch 00004: val_loss improved from 0.75909 to 0.06145, saving model to FraudDetectionModelD.h5\nEpoch 5/10\n6231/6231 [==============================] - 6s 1ms/step - loss: 0.7817 - accuracy: 0.9970 - val_loss: 0.1275 - val_accuracy: 0.9985\n\nEpoch 00005: val_loss did not improve from 0.06145\nEpoch 6/10\n6231/6231 [==============================] - 6s 1ms/step - loss: 0.8515 - accuracy: 0.9968 - val_loss: 2.1484 - val_accuracy: 0.9986\n\nEpoch 00006: val_loss did not improve from 0.06145\nEpoch 7/10\n6231/6231 [==============================] - 7s 1ms/step - loss: 0.7334 - accuracy: 0.9976 - val_loss: 1.5772 - val_accuracy: 0.9986\n\nEpoch 00007: val_loss did not improve from 0.06145\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\nEpoch 8/10\n6231/6231 [==============================] - 6s 1000us/step - loss: 0.6623 - accuracy: 0.9981 - val_loss: 0.0786 - val_accuracy: 0.9985\n\nEpoch 00008: val_loss did not improve from 0.06145\nEpoch 9/10\n6231/6231 [==============================] - 6s 1ms/step - loss: 0.1029 - accuracy: 0.9982 - val_loss: 0.0764 - val_accuracy: 0.9986\n\nEpoch 00009: val_loss did not improve from 0.06145\nEpoch 10/10\n6231/6231 [==============================] - 6s 966us/step - loss: 0.1066 - accuracy: 0.9983 - val_loss: 0.0736 - val_accuracy: 0.9987\n\nEpoch 00010: val_loss did not improve from 0.06145\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelD.evaluate(X_test, Y_test)[1]","execution_count":59,"outputs":[{"output_type":"stream","text":"1336/1336 [==============================] - 1s 772us/step - loss: 0.0811 - accuracy: 0.9985\n","name":"stdout"},{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"0.9985018968582153"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# That's crazy, how did a simple perceptron do better than a DNN. Make's me wonder if RandomForest of XGBoost can make this even better.\n# Lets try RandomForest and XGB","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Won't be needing validation\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 42)","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 25)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RandomForest acc: \", metrics.accuracy_score(y_test, y_pred)) ","execution_count":63,"outputs":[{"output_type":"stream","text":"RandomForest acc:  0.999602073897218\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Wow!! I knew that perceptron idea was going somewhere, lets try XGBoost.","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XG = xgb.XGBClassifier() \nXG.fit(X_train, y_train)\ny_pred = XG.predict(X_test) ","execution_count":65,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:29:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('XGBoost acc: ', metrics.accuracy_score(y_test, y_pred))","execution_count":66,"outputs":[{"output_type":"stream","text":"XGBoost acc:  0.9996722961506501\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks like we have a winner! I could try hyper param tuning next using grid search or bayesian opt to make it even better, but as it stands a rounded accuracy of 99.96% is very good!\n# This may take awhile but I'm going to do some cross validation to get an average accuracy across my data. Sometimes 99.96% Can be too good to be true as a general accuracy.","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nAvgAcc = print(cross_val_score(XG, X_test, y_test, cv=10, scoring='accuracy').mean())","execution_count":72,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:33:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:33:27] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:33:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:33:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:34:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:34:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:34:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:34:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:34:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"stream","text":"[04:35:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n0.9995318543818472\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Okay if you can't see it cause of the hoopla,\n# Our avg acc was '99.953%'","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# That was a lot higher than I expected. Little to no change!\n# So to finalize it all, the best model was XGBoost with a generalized accuracy of 99.953% across 10 seperate folds.\n# I'm very happy with the results especially when the generalized acc is above 99.95% That's crazy to me! ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}