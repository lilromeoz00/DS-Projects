### Silicon Valley is a super funny show and one of my favorite episodes is when they were creating a "Seefood" app which would determine what kind of food an image is looking at. The launch didn't go quite as expected. It's one of my favorite scenes of the show. Please watch it here : https://www.youtube.com/watch?v=vIci3C4JkL0
### I've always wanted to do it even if it was a more simple project, it's still fun to see a funny idea come to life!
### So I did this project after the emotion and gender CNNs. When I first trained the model, I couldn't get above 71% on my test set even though I saw validation reaching upwards of 85%. Remembering callbacks were a thing, I implemented it and my test set accuracy went up to XX%! This was a fairly small dataset so if I got my high quality images I'd be able to reach a higher accuracy. I think It's generalizing food well, so I might have to add filters to the model that detects the edges of a bun & hotdog more. This was a fun project, never thought I'd be able to make it after watching that episode!
